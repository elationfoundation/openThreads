List-servs are important for digital communities. Their archives are important repositories of a history of digital community. I will be exploring how to take the text based list-serv archive and derive some understanding about the community behind it. I will be using the language python because it leads itself to explanation better than the cursory explorations of list-serv archives I did using bash and regular expressions.


The first thing we need to explore is the header of an e-mail. 

From davis at cs.ucsc.edu  Tue Dec  1 01:10:28 2009
From: davis at cs.ucsc.edu (James Davis)
Date: Tue, 01 Dec 2009 01:10:28 -0800
Subject: [liberationtech] Silicon Sweatshops (fwd)
In-Reply-To: <22730182.1259652770827.JavaMail.root@n26>
References: <Pine.LNX.4.64.0911302314200.8174@symsyspg.Stanford.EDU>
	<22730182.1259652770827.JavaMail.root@n26>
Message-ID: <4B14DD84.8080001@cs.ucsc.edu>



Let's open the file and create a raw text version we can manipulate

>>> f = open("/home/s2e/testing/libtech/mailman.stanford.edu/pipermail/liberationtech/2009-December.txt")
>>> raw = f.read()

Now we import our regular expressions (magic) to begin to parse the text

>>> import re

Lets find all the chunks of text that match the first line of a message like this "From davis at cs.ucsc.edu  Tue Dec  1 01:10:28 2009". We do this by capturing any text that starts with 'From', has some ammount of other text, and is ended by four didgits.

>>> messages = re.findall('Find.*\d\d\d\d', raw)
>>> for i in(messages): print(i)

This is a very sloppy regular expression. Lets see if we can firm it up a bit? To do this I have added the match only at the beggining (^) and the end($) of line regular expression charicters. To use these charicters I have to use the MULTILINE flag in my re.findall command.

>>>names = re.findall('^From.* \d\d\d\d$', raw, flags=re.MULTILINE)

We now have the first line of every message. Lets split this into its component parts. To do this we will have to see what is "regular" about our expressions and take advantage of it.

From davis at cs.ucsc.edu  Tue Dec  1 01:10:28 2009

The long form regular format of these e-mails looks like this:
"From"<space><user name><space>"at"<space><domain name><space><day><space><month><number><space><number><colon><number><colon><number><space><number>

The e-mail address looks like <user name><space>"at"<space><domain name>.
The date looks like <day><space><month><number><space><number><colon><number><colon><number><space><number>.

For my purposes I care about who sent what, and when they sent it. Because I just need to see the messsages in relation to each other, and don't care about the human readable version of the date I am going to cut that out. To specify the components of the regular expression I want returned to me I surround those expressions in parenthesis ().


>>> names = re.findall('^From\s(.*\sat\s.*)\s*([A-Z][a-z]{2}\s[A-Z][a-z]{2}\s\d.*\d{4}$)', raw, flags=re.MULTILINE)

But now we are getting to crazy long regular expressions. This regular expression is technically correct. I like to split mine up into easy to use chunks in order to make my code more readable. 

>>> who = '(.*\sat\s.*)'
>>> headerFront = '^From\s' + who + '\s*'
>>> day = '[A-Z][a-z]{2}'
>>> month = day
>>> date = '(' + day + '\s' + month + '\s\d.*\d{4}$)'
>>> topHeader = headerFront + date
>>> nameNdate = re.findall(topHeader, raw, flags=re.MULTILINE)

Ahhhh, thats better. You will notice that I kept the text captures in the named regular expressions so that I only took the data I wanted. This way I can reuse the who value later when I am parsing through the file.

Since I have the first line parsed the way I want it, now it is time to start grabbing text in relation to that first line. When we were only searching for one line it was nice to have the ability to use ^ and $ to identify the begginging and end of the line. Because we will be working across lines I am going to remove that in order to have . match newlines. To do this I will use the DOTALL flag with re.DOTALL.

First I will replace my ^ and $ chars with \n on the regex I have. 

>>> headerFront = '\nFrom\s' + who + '\s*'
>>> date = '(' + day + '\s' + month + '\s\d.*\d{4})\n'

now I will change my flags to include dots matching all (hint: you can also use re.S to do the same thing. re.DOTALL is just easier to read)

>>> nameNdate = re.findall(topHeader, raw, flags=re.DOTALL)

EVERYTHING IS RUINED! It captured everything... oh yea, with periods capturing everything there are a bunch of new interesting results. Lets refine our regular expressions to really focus down what we want.

First we will replace periods that we don't want matching new lines with \S which matches all non white-space characters. I am also going to remove the built-in captures so that I can define my captures when I call the function. This will allow me to specify what I want to capture in the future.

>>> who = '\S*\sat\s\S*'
>>> date = day + '\s' + month + '\s{2}\d*\s\S*?\d{4}$'

With that I can construct a regular expression parser that will let me create a collection that presents me with who a e-mail to a list is from, what date it was sent, and then the contents (including the other header info)

>>> who = '\S*\sat\s\S*'
>>> headerFront = '^From\s' + who + '\s*'
>>> capturedFront = >>> headerFront = '^From\s(' + who + ')\s*'
>>> day = '[A-Z][a-z]{2}'
>>> month = day
>>> date = day + '\s' + month + '\s{2}\d*\s\S*?\d{4}$'
>>> capHeader = capturedFront + '(' date ')'
>>> dropHeader = headerFront + date

>>>emailList = re.findall(capHeader + '(.*?)' + dropHeader, raw, flags=re.DOTALL)


For testing purposes I have taken all of the single lines of text and put them in a set of functions to make it easier to quickly modify and check changes in the code. I decided to wrap all my functions in a class so that I will be able to manipulate multiple listServ files on the command line to ensure that my code does not just run on a single test file.
<code>
import re
class converter:
    def __init__(self):
        self.raw = ''

    def getArchive(self, textFile):
        """This function takes the location of the list-serv text file and opens it up for parsing. Much later I may add the ability to just choose the html address of a list-serv archive. That will be straight up neato!
        """
        text = open(textFile)
        rawText = text.read()
        self.raw = rawText
    

    def printMessage(self):
    	""" This function parses an archive and prints out the results of a generic regular expression. For testing purposes only. Will be converted into a generic dictionary generator that parses the text-file.
""" 
	if self.raw == ''
	   print("Please get a list serv archive and import it file first.")
        who = '\S*\sat\s\S*'
        headerFront = '\nFrom\s' + who + '\s*'
        capturedFront = '\nFrom\s(' + who + ')\s*'
        day = '[A-Z][a-z]{2}'
        month = day
        date = day + '\s' + month + '\s*?\d*?\s\S*?\s\d{4}\n'
        capHeader = capturedFront + '(' + date + ')'
        dropHeader = headerFront + date
#TODO - create captures for all header sections
#TODO - rewrite the following line to become a dictionary that parses the monthly log and create indiviudal dictionaries of all pertinant header info for each e-mail and includes the content.
        messageDict = re.findall(capHeader, self.raw, flags=re.DOTALL)
        print messageDict
</code>

Now that I have my quick regular expression parser I can just change the messageDict to examine my progress. I created a small one liner to reload my function, create a class object, run the function that grabs the text, and run a test print of my regular expression.

>>> reload(main); a=main.converter(); a.getArchive('testText'); a.printMessage()

Now the next step is to capture the rest of the information and put it in a format that is easy to manipulate. To do this we are going to create a dictionary from the parsed data. Since you have a good understanding of Regular Expressions now I will try to only go in-depth when discussing new concepts. Here is our header again.


From davis at cs.ucsc.edu  Tue Dec  1 01:10:28 2009
From: davis at cs.ucsc.edu (James Davis)
Date: Tue, 01 Dec 2009 01:10:28 -0800
Subject: [liberationtech] Silicon Sweatshops (fwd)
In-Reply-To: <22730182.1259652770827.JavaMail.root@n26>
References: <Pine.LNX.4.64.0911302314200.8174@symsyspg.Stanford.EDU>
	<22730182.1259652770827.JavaMail.root@n26>
Message-ID: <4B14DD84.8080001@cs.ucsc.edu>


I have repeated a list-serv header above to remind you what it looks like. At first glance it looks easy enough to parse out the contents of the header using a sreies of regular expressions for each line such as this.

>>> whom = 'From\:\s(.*?)\n'
>>> date = 'Date\:\s(.*?)\n'
>>> subject = 'Subject\:\s(.*?)\n'
>>> inReply = 'In\-Reply\-To\:\s(.*?)\n'
>>> refrences = 'Refrences\:\s(.*?)\n'
>>> messageID = 'Message\-ID\:\s(.*?)\n'
>>> headerChunks = from + date + subject + inReply + refrences + messageID
>>> messageDict = re.findall(headerChunks, self.raw, flags=re.DOTALL)

This won't get all the data. Even worse, it will be all sorts of slow. In fact, I did that set of regular expressions just for your benefit. Not saying that you owe me or anything. I am just saying. So, why won't that work? Think back to your past e-mails, look at our example header, and think about what re.findall does and returns. It is not because I am not grabbing the surrounding text. If you figured out that not every message in in reply to somthing you were right on. The first e-mail in a archive will not have this section. Refrences are the same way. So, we have to come up with a better way to deal with these cases. 

Since we know that a header will always have our archive specific front matter, which is repeated in the header, and a message ID we can safely identify the bounds of the header and grab just it. 

>>> headerFront = '\nFrom\s' + who + '\s*'
>>> day = '[A-Z][a-z]{2}'
>>> month = day
>>> date = day + '\s' + month + '\s*?\d*?\s\S*?\s\d{4}\n'
>>> dropTop = headerFront + date
>>> getHeader = '(.*?Message\-ID\:\s.*?\n)'
>>> messageDict = re.findall(dropTop + getHeader, self.raw, flags=re.DOTALL)


Now we have a function that only grabs the header of an e-mail from a list-serv. But, notice how we are dropping the archive specific front matter. Well, lets use that and pythons regular expression "split" function to parse our e-mails out a bit further. 

<code>
        splitText = re.split(dropTop, self.raw)
</code>

Using the split function we have creates a list of e-mails. This is the obviousl better way to do things. That is, of course, unless somone has the nerve to copy and paste a list-serv message into the text of an e-mail. If that happened, the e-mail would be split up. For instance, if I pasted the text of this article into an e-mail it would probobly match a whole bunch of stuff that it is not supposed to and, therefore, cut it into ribbons and ruin my data. Just warning you. 


The next step will be to fully parse the headers of a message. Remember when I made you feel all bad about how much extra work I did just to show you what thoseregular expressions for each line would look like. That was a lie. I am going to use those right now. Let that be a lesson to you. Humans are mischevous little devils and should not be trusted. But, on to the lesson. Now that we have split apart our e-mails we can easily pass them to a function that identifies the header sections and splits them apart. In order to make the next section easier, i am also going to use this function to create a dictionary out of split up components.

<code>
    def dictify(self, email):
        #get headers from email
        getHeader = '(.*?Message\-ID\:\s.*?\n)'
        msgDict = {}
        msg = re.findall(getHeader + '(.*)', email, flags=re.DOTALL)
        #create a dictionary item for body text
        for i in msg:
            msgDict['body'] = i[1]
        # Setting header specific regEx's
        whom = 'From\:\s(.*?)\n'
        date = 'Date\:\s(.*?)\n'
        subject = 'Subject\:\s(.*?)\n'
        inReply = 'In\-Reply\-To\:\s(.*?)\n'
        references = 'References\:\s(.*?)\nMessage\-ID\:'
        messageID = 'Message\-ID\:\s(.*?)\n'

        #create a dictionary item for the header items that are always there.
        msgDict['From'] = re.findall(whom, email, flags=re.DOTALL)
        msgDict['Date'] = re.findall(date, email, flags=re.DOTALL)
        msgDict['Subject'] = re.findall(subject, email, flags=re.DOTALL)
        msgDict['ID'] = re.findall(messageID, email, flags=re.DOTALL)

        #create checks for items that may not be there.
        if re.search(references, email, flags=re.DOTALL) != 'none':
            msgDict['References'] = re.findall(references, email, flags=re.DOTALL)
        if re.search(inReply, email, flags=re.DOTALL) != 'none':
            msgDict['Reply'] = re.findall(inReply, email, flags=re.DOTALL)
	#split up refrences into a list within its dict item for easy parsing later
        if msgDict['References'] != []:
            msgDict['References'] = re.split('\s*|\n\t', msgDict['References'][0])

	#remember we are just printing out sections to check for consistancy. I created a simple 'Refrences' to ID printout here to look at how a reply links to the refrences before it.
        print("--------------------------")
        print("=======NEW EMAIL=========")
        print("--------------------------")
        print("==========ID==============")
        print(msgDict['ID'])
        print("==========Reply To==============")
        print(msgDict['Reply'])
        print("=========Refrences==========")
        print(msgDict['References'])
</code>



['Body': ["ALLL SORTS OF BODY TEXT"],
 'From': ['bishop at designafternext.com (Bishop Zareh)'],
 'Refrences': ['<50E0B2B7.7010304@entersection.org>'],
 'Date': ['Mon, 31 Dec 2012 18:09:37 -0600'],
 'Reply': ['<50E0B2B7.7010304@entersection.org>'],
 'ID': ['<07080613-2615-4B02-BD9D-8024FD1CD62E@designafternext.com>', '<50E0B2B7.7010304@entersection.org>'],
 'Subject': ["[liberationtech] Jacob Appelbaum's 29C3 keynote"]


Well, that is it for parsing the e-mail headers. In the next piece I will go in more depth about how we parse the body text to make it easier to connect in-line responses to their initial message and how we refactor our hacked up code to better expose our list-serv parsers API for content analysis.


Lets look at the "regular" parts of a body message:

First lets start with PGP signatures. Below is a PGP signature I pulled from Lib tech. (I changed a few chars to make it gibberish.) 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)

iQEcBAEBAgAGBQJ9bCs0AAoJEBEET9GfxSfMgKEH/1rGH6GNm0DpPO6lnFJnTBvH
kEnNSjU3b5BuYIw39wYfG3GE3sOsFuTnt0/KMWGB9M+-XqpNo08Yt3HXUfv2Lii0
eIm9JOLb1/CfmnCyenVgkYKs2vORQmolAMSu+pqxuY1hb4GwffRG+uY5wu6jA4fc
CpdQz8ylPmoEfptbIpAhvu52t2QAPcOvHKSs3xA4hafeDLXG7mebmG7Rbft+gs9G
v8w4NMxrXiKoB/v7kR7ZOO7Jr1uRLUMn6prhVS+99v46dPyxGZDjiXO+VRohC2DG
LsqkgyhdGY8a1FXVeUAKVc0YTud4I1E1d135TqqpE9DsFmh/QgEP2QSk/XZl1zg=
=bWOj
-----END PGP SIGNATURE-----

Using the regular expression tools I have described earlier I first created a redular expression that could capture the header and footer.

beginPGP = '\-{5}[A-Z]{5} [A-Z]{3} [A-Z]{9}\-{5}\n'
endPGP = '\-{5}[A-Z]{3} [A-Z]{3} [A-Z]{9}\-{5}\n'

Since this is a static statement I could have simply typed out the whole statement in the regular expression with proper escaping of the -'s. That would be less fun though. Once I have my capture for the pgp header and footer I simply captured all that was between them.

PGP = beginPGP + '(.*?)' + endPGP

You can check the results using this simple test.

test = re.findall(PGP, msgDict['body'], flags=re.DOTALL)

Scrubbed attachements work the same way.

-------------- next part --------------

scrubbed = '\-{14}\s[a-z]{4}\s[a-z]{4}\s\-{14}'
grabScrubbed = scrubbed + '(.*)'

Since scrubbed attachements are always the last bit of data on the message I have allowed my wildcard to be as greedy as it wants.

Finally we are moving to more complex parsing, capturing reply's. Reply's have a consitant format of using increasing >'s as a way of specifying how many e-mails ago the text came from. a line starting with one > signifies the last messages text. Two >> signifies that that text is a reply to another reply. Three >> is a reply, to a reply, to a reply, and so on.  Below are some examples.

In-Line replys:
On 10/6/12 10:36 PM, Collin Anderson wrote:
> It'll also be really useful to know of 'piratepad' type platforms
> that are secure, and there's controls over deleting the
> collaborative pads/docs.


Nested In-Line replys:
On 10/6/12 10:36 PM, Collin Anderson wrote:
> On Sat, Oct 6, 2012 at 4:45 PM, Fabio Pietrosanti (naif) <
> lists at infosecurity.ch> wrote:
> Hello,
>> If you're looking to use it all the time (eg with your class, group,
>> organization), then it might be worthwhile to host your own [1].
> I advise against it. While many groups started to do that only few
> services are left operational. Most servers went down to their knews.


Notice that the reply header is determinant on the mail client that sends it.

On Oct 5, 2012, at 7:02 AM, Katy P <katycarvt at gmail.com> wrote:
On 10/6/12 10:36 PM, Collin Anderson wrote:
On Sat, Oct 6, 2012 at 4:45 PM, Fabio Pietrosanti (naif) <lists at infosecurity.ch> wrote:

But, the basic structure starting with 'On' and ending with 'wrote:' allows us to capture this data in case we want to play with it later.

replyName = 'On\s(.*?)wrote\:'

Finally we get to the meat of the reply's.




